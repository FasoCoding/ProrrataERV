{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prorrata ERNC\n",
    "Este programa tiene por objetivo realizar el re-calculo de curtailment para el sistema, en base a metodología propuesta por la NTCyO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LECTURA DE DATOS\n",
    "Los datos deben ser extraidos desde el accdb en potencia neta (no por la potencia, sino por los marginales no truncados). La lista de datos que se deben extraer son:\n",
    "1. Generación de cada central.\n",
    "2. Perfil de generación de cada central.\n",
    "3. Barra asociada a cada central.\n",
    "4. Costos marginales para cada.\n",
    "5. Curtailment por central (quizas por barra es suficiente).\n",
    "6. Potencia máxima.\n",
    "7. Generación disponible.\n",
    "8. Estado de operación.\n",
    "\n",
    "Para la lectura, a modo de determinar la mejor query al sistema, sin tener que lidiar con los problemas de MS Access, se cargan las tablas en DuckDB y se utiliza jupysql para probar SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import duckdb as duck\n",
    "\n",
    "from pathlib import Path\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "from sqlalchemy import (\n",
    "    engine,\n",
    "    create_engine,\n",
    "    inspect\n",
    ")\n",
    "\n",
    "path_prg = Path(r\"../data/Model PRGdia_Full_Definitivo Solution.accdb\").absolute()\n",
    "\n",
    "if not path_prg.exists():\n",
    "    raise ValueError(f\"Path: {path_prg} does not exists.\")\n",
    "\n",
    "connection_string = (\n",
    "    r\"DRIVER={Microsoft Access Driver (*.mdb, *.accdb)};\"\n",
    "    rf\"DBQ={path_prg.as_posix()};\"\n",
    "    r\"ExtendedAnsiSQL=1;\"\n",
    ")\n",
    "connection_url = engine.URL.create(\n",
    "    \"access+pyodbc\",\n",
    "    query={\"odbc_connect\": connection_string}\n",
    ")\n",
    "\n",
    "try:\n",
    "    prg_engine = create_engine(connection_url)\n",
    "    tables = inspect(prg_engine).get_table_names()\n",
    "\n",
    "    conn = duck.connect(\"PCP.duckdb\")\n",
    "    #conn.execute(\"CREATE SCHEMA IF NOT EXISTS bronze\")\n",
    "\n",
    "    for table in tables:\n",
    "        print(f\"trabajando en tabla: {table}...\")\n",
    "        df = pl.read_database(query=f\"SELECT * FROM {table}\", connection=prg_engine)\n",
    "        conn.execute(f\"CREATE OR REPLACE TABLE {table} AS SELECT * FROM df\")\n",
    "\n",
    "except SQLAlchemyError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "finally:\n",
    "    conn.close()\n",
    "    prg_engine.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REVISIÓN DUCKDB\n",
    "Con la data carga en la base de datos, empezamos a mirar como armar la mejor query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esto es para carga la extensión y leer la base de datos.\n",
    "import duckdb\n",
    "\n",
    "conn_pcp = duckdb.connect(\"pcp.duckdb\")\n",
    "\n",
    "# load de la extensión para sql\n",
    "%load_ext sql\n",
    "%sql conn_pcp --alias duck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esto es para cerrar las conexiones, usarlo al terminar de revisar\n",
    "%sql --close duck\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clasica query para sacar la generación, levemente modificada para sacar las otras propiedades de una, no es necesario tener una query por dato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT \n",
    "    t_child.name AS generator,\n",
    "    t_property.name AS property,\n",
    "    t_period_0.datetime,\n",
    "    t_data_0.key_id AS data_key,\n",
    "    t_data_0.period_id AS data_period,\n",
    "    t_data_0.value,\n",
    "FROM ((((((((t_membership\n",
    "INNER JOIN t_collection ON t_membership.collection_id = t_collection.collection_id)\n",
    "INNER JOIN t_object AS t_parent ON t_membership.parent_object_id = t_parent.object_id)\n",
    "INNER JOIN t_object AS t_child ON t_membership.child_object_id = t_child.object_id)\n",
    "INNER JOIN t_property ON t_collection.collection_id = t_property.collection_id)\n",
    "INNER JOIN t_key ON t_membership.membership_id = t_key.membership_id AND t_property.property_id = t_key.property_id)\n",
    "INNER JOIN t_data_0 ON t_key.key_id = t_data_0.key_id)\n",
    "INNER JOIN t_phase_3 ON t_data_0.period_id = t_phase_3.period_id)\n",
    "INNER JOIN t_period_0 ON t_phase_3.interval_id = t_period_0.interval_id)\n",
    "INNER JOIN t_category ON t_child.category_id = t_category.category_id\n",
    "WHERE t_collection.collection_id = 1 AND t_property.property_id IN (1, 28, 200, 219) AND t_category.category_id IN (95, 96, 99, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar a la anterior, una query para sacar los datos con marginales negativos, no se necesita el resto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT \n",
    "    t_child.name AS node,\n",
    "    t_period_0.datetime,\n",
    "    t_data_0.key_id AS data_key,\n",
    "    t_data_0.period_id AS data_period,\n",
    "    t_data_0.value AS marginal_cost,\n",
    "FROM ((((((((t_membership\n",
    "INNER JOIN t_collection ON t_membership.collection_id = t_collection.collection_id)\n",
    "INNER JOIN t_object AS t_parent ON t_membership.parent_object_id = t_parent.object_id)\n",
    "INNER JOIN t_object AS t_child ON t_membership.child_object_id = t_child.object_id)\n",
    "INNER JOIN t_property ON t_collection.collection_id = t_property.collection_id)\n",
    "INNER JOIN t_key ON t_membership.membership_id = t_key.membership_id AND t_property.property_id = t_key.property_id)\n",
    "INNER JOIN t_data_0 ON t_key.key_id = t_data_0.key_id)\n",
    "INNER JOIN t_phase_3 ON t_data_0.period_id = t_phase_3.period_id)\n",
    "INNER JOIN t_period_0 ON t_phase_3.interval_id = t_period_0.interval_id)\n",
    "INNER JOIN t_category ON t_child.category_id = t_category.category_id\n",
    "WHERE t_collection.collection_id = 245 AND t_property.property_id = 1233 AND t_data_0.value < 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query bonita con CTE para extraer la relación entre barra y generador. Lamentablemente no hay CTE en MSACCESS por lo que se reformula en el .sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "WITH node_obj AS (\n",
    "    SELECT \n",
    "        t_object.object_id AS node_id,\n",
    "        t_object.name AS node,\n",
    "    FROM t_object\n",
    "    INNER JOIN t_class ON t_object.class_id = t_class.class_id\n",
    "    WHERE t_class.name = 'Node'\n",
    "), gen_obj AS (\n",
    "    SELECT \n",
    "        t_object.object_id AS gen_id,\n",
    "        t_object.name AS generator,\n",
    "    FROM t_object\n",
    "    INNER JOIN t_class ON t_object.class_id = t_class.class_id\n",
    "    WHERE t_class.name = 'Generator' AND t_object.category_id IN (95, 96, 99, 100)\n",
    ")\n",
    "\n",
    "SELECT\n",
    "    node_obj.node,\n",
    "    gen_obj.generator,\n",
    "FROM t_membership\n",
    "INNER JOIN node_obj ON t_membership.child_object_id = node_obj.node_id\n",
    "INNER JOIN gen_obj ON t_membership.parent_object_id = gen_obj.gen_id\n",
    "WHERE t_membership.collection_id = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Juntando la información\n",
    "Con el trabajo de armar los SQL, ahora se pasa a solo usar polars para disminuir la necesidad de otra libreria `DuckDB` (por mucho que me guste esta db)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "from pathlib import Path\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "from sqlalchemy import (\n",
    "    engine,\n",
    "    create_engine,\n",
    ")\n",
    "\n",
    "# Lectura de SQL Barra-Generador\n",
    "path_sql_node = Path(r\"../poc_prorrataerv/sql/gen_node.sql\").absolute()\n",
    "with open(path_sql_node, \"r\") as file:\n",
    "    sql_node = file.read()\n",
    "\n",
    "# Lectura de SQL con data de generacion\n",
    "path_sql_gen = Path(r\"../poc_prorrataerv/sql/gen_data.sql\").absolute()\n",
    "with open(path_sql_gen, \"r\") as file:\n",
    "    sql_gen = file.read()\n",
    "\n",
    "# lectura de SQL con data de barras con costos marginales menor a 0\n",
    "path_sql_cmg = Path(r\"../poc_prorrataerv/sql/cmg_data.sql\").absolute()\n",
    "with open(path_sql_cmg, \"r\") as file:\n",
    "    sql_cmg = file.read()\n",
    "\n",
    "# Inicio de captura de datos en dataframes\n",
    "path_prg = Path(r\"../data/Model PRGdia_Full_Definitivo Solution.accdb\").absolute()\n",
    "\n",
    "if not path_prg.exists():\n",
    "    raise ValueError(f\"Path: {path_prg} does not exists.\")\n",
    "\n",
    "connection_string = (\n",
    "    r\"DRIVER={Microsoft Access Driver (*.mdb, *.accdb)};\"\n",
    "    rf\"DBQ={path_prg.as_posix()};\"\n",
    "    r\"ExtendedAnsiSQL=1;\"\n",
    ")\n",
    "connection_url = engine.URL.create(\n",
    "    \"access+pyodbc\",\n",
    "    query={\"odbc_connect\": connection_string}\n",
    ")\n",
    "\n",
    "try:\n",
    "    prg_engine = create_engine(connection_url)\n",
    "\n",
    "    df_nodes = pl.read_database(query=sql_node, connection=prg_engine)\n",
    "    df_gen = pl.read_database(query=sql_gen, connection=prg_engine)\n",
    "    df_cmg = pl.read_database(query=sql_cmg, connection=prg_engine)\n",
    "\n",
    "except SQLAlchemyError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "finally:\n",
    "    prg_engine.dispose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura de otros datos pmgd\n",
    "path_pmgd = Path(r\"W:/41 Dpto Pronosticos/Vertimiento_ERNC/Lista_PMGDs.xlsx\").absolute()\n",
    "df_pmgd = pl.read_excel(\n",
    "    source=path_pmgd,\n",
    "    sheet_name=\"Hoja1\",\n",
    "    xlsx2csv_options={\"skip_empty_lines\": True},\n",
    "    read_csv_options={\"new_columns\": [\"Nombre_CDC\",\"Centrales\"]},\n",
    ")\n",
    "\n",
    "# lectura de lista de centrales vetadas\n",
    "path_vetados = Path(r\"R:/Aplicaciones/Prorrateo_Vertimiento/Centrales_Vetadas.xlsx\").absolute()\n",
    "df_vetados = pl.read_excel(\n",
    "    source=path_vetados,\n",
    "    sheet_name=\"Hoja1\",\n",
    "    xlsx2csv_options={\"skip_empty_lines\": True},\n",
    "    read_csv_options={\"new_columns\": [\"Centrales\"]},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check errores de curtailement por centrales no pintadas en rojo.\n",
    "(\n",
    "    df_gen\n",
    "    .filter(\n",
    "        pl.col(\"generator\").is_in(\n",
    "            pl.concat(\n",
    "                [df_vetados[\"Centrales\"].unique(),\n",
    "                 df_pmgd[\"Centrales\"].unique()]\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    .pivot(\n",
    "        values=\"value\",\n",
    "        columns=\"property\",\n",
    "        index=[\"generator\", \"datetime\"]\n",
    "    )\n",
    "    .filter(\n",
    "        pl.col(\"Units Generating\") == 1,\n",
    "        pl.col(\"Capacity Curtailed\") != 0,\n",
    "    )\n",
    "    .select(\n",
    "        pl.exclude(\"Units Generating\")\n",
    "    )\n",
    "    .group_by(pl.col(\"generator\").alias(\"Generator\"))\n",
    "    .agg(pl.col(\"Capacity Curtailed\").sum().alias(\"Total Capacity Curtailed\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformación de data para generación, eliminando centrales vetadas y pmgd\n",
    "# y pivotear la data para tener las columnas de las propiedades\n",
    "# y filtrar las centrales que no estan generando\n",
    "df_gen_pivot = (\n",
    "    df_gen\n",
    "    .filter(\n",
    "        ~pl.col(\"generator\").is_in(df_vetados[\"Centrales\"].unique()),\n",
    "        ~pl.col(\"generator\").is_in(df_pmgd[\"Centrales\"].unique()),\n",
    "    )\n",
    "    .pivot(\n",
    "        values=\"value\",\n",
    "        columns=\"property\",\n",
    "        index=[\"generator\", \"datetime\"]\n",
    "    )\n",
    "    .filter(\n",
    "        pl.col(\"Units Generating\") == 1,\n",
    "    )\n",
    "    .select(\n",
    "        pl.exclude(\"Units Generating\")\n",
    "    )\n",
    ")\n",
    "df_gen_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_error(df: pl.LazyFrame, original_col: str = \"Generation\", prorrata_col: str = \"Prorrata\", over_col: str = \"datetime\") -> pl.LazyFrame:\n",
    "    return (\n",
    "        df\n",
    "        .with_columns(\n",
    "            pl.when(pl.col(\"Prorrata\").lt(0))\n",
    "            .then(pl.col(\"Prorrata\").abs())\n",
    "            .otherwise(0)\n",
    "            .alias(\"Error\"),\n",
    "            pl.when(pl.col(\"Prorrata\").lt(0))\n",
    "            .then(0)\n",
    "            .otherwise(pl.col(\"Prorrata\"))\n",
    "            .alias(\"Prorrata\"),\n",
    "        )\n",
    "    )\n",
    "\n",
    "def check_error(df: pl.LazyFrame, error_col: str = \"Error\", tol: float = 1e-3) -> bool:\n",
    "    return df.select(pl.col(error_col).ge(tol).any()).collect().item()\n",
    "\n",
    "def show_total_error(df: pl.LazyFrame, error_col: str = \"Error\") -> float:\n",
    "    return df.select(pl.col(error_col).sum().alias(\"Total Error\")).collect().item()\n",
    "\n",
    "def calc_prorrata(df: pl.LazyFrame, target_col: str = \"Prorrata\", error_col: str = \"Error\", weight_col: str = \"Max Capacity\", over_col: str = \"datetime\") -> pl.LazyFrame:\n",
    "    return (\n",
    "        df\n",
    "        .with_columns(\n",
    "            (pl.col(target_col) - pl.col(error_col).sum().over(over_col) * pl.col(weight_col) / pl.col(weight_col).sum().over(over_col)).alias(\"Prorrata\"),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_prorrata(df: pl.LazyFrame, target_col: str = \"Prorrata\", error_col: str = \"Error\", weight_col: str = \"Max Capacity\", over_col: str = \"datetime\") -> pl.LazyFrame:\n",
    "    df_processed = calc_prorrata(df,target_col,error_col)\n",
    "    df_processed = calc_error(df_processed)\n",
    "\n",
    "    print(check_error(df_processed))\n",
    "    print(show_total_error(df_processed))\n",
    "\n",
    "    if check_error(df_processed):\n",
    "        return process_prorrata(df_processed)\n",
    "    \n",
    "    return df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = (\n",
    "    df_cmg\n",
    "    .join(df_nodes, on=\"node\", how=\"inner\")\n",
    "    .join(df_gen_pivot, on=[\"generator\",\"datetime\"], how=\"inner\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prorrata_func = process_prorrata(test_data.lazy(),\"Available Capacity\",\"Capacity Curtailed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prorrata_func.collect().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    test_prorrata_func\n",
    "    .sort(by=\"datetime\")\n",
    "    .group_by(\"datetime\")\n",
    "    .agg(\n",
    "        #pl.col(\"Prorrata_Curt\").sum().alias(\"Total_Curatiled\"),\n",
    "        pl.col(\"Generation\").sum().alias(\"Total_Gen\"),\n",
    "        pl.col(\"Prorrata\").sum().alias(\"Total_Gen_Prorrata\"),\n",
    "        #pl.col(\"Prorrata\").min().alias(\"Min_Gen_Prorrata\"),\n",
    "        #pl.col(\"Prorrata\").filter(pl.col(\"Prorrata\").lt(0)).sum().alias(\"Sum_Gen_Prorrata\"),\n",
    "        pl.col(\"Error\").sum().alias(\"Total_Error\"),\n",
    "        (pl.col(\"Prorrata\") - pl.col(\"Error\")).sum().alias(\"Sum_Prorrata_error\"),\n",
    "        (pl.col(\"Generation\") - (pl.col(\"Prorrata\") - pl.col(\"Error\"))).sum().alias(\"Test_total\"),\n",
    "    )\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prorrata_func.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_update = (\n",
    "    test_prorrata_func\n",
    "    .join(\n",
    "        df_gen.filter(pl.col(\"property\") == \"Generation\").lazy(),\n",
    "        on=[\"generator\",\"datetime\"],\n",
    "        how=\"inner\"\n",
    "    )\n",
    "    .select(\n",
    "        #pl.col(\"generator\"),\n",
    "        #pl.col(\"datetime\"),\n",
    "        #pl.col(\"Generation\"),\n",
    "        #pl.col(\"value\").alias(\"Generation_Ori\"),\n",
    "        pl.col(\"data_key\").alias(\"key_id\"),\n",
    "        pl.col(\"data_period\").alias(\"period_id\"),\n",
    "        pl.col(\"Prorrata\").alias(\"value\"),\n",
    "    )\n",
    "    .sort(by=[\"key_id\",\"period_id\"])\n",
    "    .collect()\n",
    ")\n",
    "data_to_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = data_to_update.head().to_dicts()\n",
    "for row in test_dict:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import (\n",
    "    engine,\n",
    "    create_engine,\n",
    "    inspect,\n",
    ")\n",
    "from sqlalchemy.sql.expression import (\n",
    "    update,\n",
    "    table,\n",
    "    column,\n",
    ")\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "df_data = pl.read_csv(\"../t_data_0.csv\")\n",
    "\n",
    "t_data_0 = table(\"t_data_0\", column(\"key_id\"), column(\"period_id\"), column(\"value\"))\n",
    "#stmt = update(t_data_0).where(t_data_0.c.key_id == 1).values(value=0.0)\n",
    "\n",
    "# Inicio de captura de datos en dataframes\n",
    "path_prg = Path(r\"../data/Model PRGdia_Full_Definitivo Solution_neto.accdb\").absolute()\n",
    "\n",
    "if not path_prg.exists():\n",
    "    raise ValueError(f\"Path: {path_prg} does not exists.\")\n",
    "\n",
    "connection_string = (\n",
    "    r\"DRIVER={Microsoft Access Driver (*.mdb, *.accdb)};\"\n",
    "    rf\"DBQ={path_prg.as_posix()};\"\n",
    "    r\"ExtendedAnsiSQL=1;\"\n",
    ")\n",
    "connection_url = engine.URL.create(\n",
    "    \"access+pyodbc\",\n",
    "    query={\"odbc_connect\": connection_string}\n",
    ")\n",
    "\n",
    "prg_engine = create_engine(connection_url)\n",
    "tables = inspect(prg_engine).get_table_names()\n",
    "\n",
    "with prg_engine.begin() as conn:\n",
    "    for row in df_data.head().to_dicts():\n",
    "        stmt = (\n",
    "            t_data_0.update()\n",
    "            .where(t_data_0.c.key_id == row.get(\"key_id\"))\n",
    "            .where(t_data_0.c.period_id == row.get(\"period_id\"))\n",
    "            .values(value=row.get(\"value\"))\n",
    "        )\n",
    "        restuls = conn.execute(stmt)\n",
    "        print(restuls.)\n",
    "    #conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "\n",
    "df_data = pl.read_csv(\"../t_data_0.csv\")\n",
    "to_update = df_data.head().to_dicts()\n",
    "\n",
    "\n",
    "path_prg = Path(r\"../data/Model PRGdia_Full_Definitivo Solution_neto.accdb\").absolute()\n",
    "\n",
    "connection_string = (\n",
    "    r\"DRIVER={Microsoft Access Driver (*.mdb, *.accdb)};\"\n",
    "    rf\"DBQ={path_prg.as_posix()};\"\n",
    "    r\"ExtendedAnsiSQL=1;\"\n",
    ")\n",
    "\n",
    "cnxn = pyodbc.connect(connection_string)\n",
    "crsr = cnxn.cursor()\n",
    "\n",
    "#sql = \"SELECT TOP 10 * FROM t_data_0 \"\n",
    "#update_sql = r\"UPDATE t_data_0 SET t_data_0.value = ? WHERE t_data_0.key_id = ? AND t_data_0.period_id = ?;\"\n",
    "#params = [(data['value'],data['key_id'],data['period_id']) for data in to_update]\n",
    "#crsr.execute(update_sql, params)\n",
    "#crsr.commit()\n",
    "#cnxn.close()\n",
    "\n",
    "try:\n",
    "    cnxn.autocommit = False\n",
    "    params = params = [(data['value'],data['key_id'],data['period_id']) for data in to_update]\n",
    "    crsr.executemany(\"UPDATE t_data_0 SET t_data_0.value = ? WHERE t_data_0.key_id = ? AND t_data_0.period_id = ?;\", params)\n",
    "except pyodbc.DatabaseError as err:\n",
    "    cnxn.rollback()\n",
    "else:\n",
    "    cnxn.commit()\n",
    "finally:\n",
    "    cnxn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(data['value'],data['key_id'],data['period_id']) for data in to_update]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.head().to_dict(as_series=False)['key_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "path_prg = Path(r\"../data/Model PRGdia_Full_Definitivo Solution_neto.accdb\").absolute()\n",
    "\n",
    "connection_string = (\n",
    "    r\"DRIVER={Microsoft Access Driver (*.mdb, *.accdb)};\"\n",
    "    rf\"DBQ={path_prg.as_posix()};\"\n",
    "    r\"ExtendedAnsiSQL=1;\"\n",
    ")\n",
    "connection_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cambio de criterio\n",
    "Ajutando código para cambiar como se calcula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from prorrata.extract import DataExtractor\n",
    "\n",
    "\n",
    "path_prg = r\"C:\\Users\\felipe.bastidas\\PyProyectos\\Test_data\\PRG20240214\"\n",
    "PATH_PMGD_EXCLUDE =  r\"C:\\Users\\felipe.bastidas\\PyProyectos\\Test_data\\Otros\\Lista_PMGDs.xlsx\"\n",
    "PATH_BANNED_GENERATORS = r\"C:\\Users\\felipe.bastidas\\PyProyectos\\Test_data\\Otros\\Centrales_Vetadas.xlsx\"\n",
    "PATH_ACCDB_INPUT = r\"Datos/Model PRGdia_Full_Definitivo Solution/Model PRGdia_Full_Definitivo Solution.accdb\"\n",
    "\n",
    "data = DataExtractor(\n",
    "    Path(path_prg).joinpath(PATH_ACCDB_INPUT),\n",
    "    Path(PATH_PMGD_EXCLUDE),\n",
    "    Path(PATH_BANNED_GENERATORS)\n",
    ")\n",
    "\n",
    "data.extract_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from prorrata.transform_cdc import DataProcessor as CDC\n",
    "from prorrata.transform import DataProcessor as ORI\n",
    "\n",
    "procesor_cdc = CDC.from_extractor(data)\n",
    "procesor_cdc.process_prorrata()\n",
    "\n",
    "procesor_ori = ORI(data)\n",
    "procesor_ori.process_prorrata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_data = (\n",
    "    procesor_cdc.data.select([\"node\",\"datetime\",\"generator\",\"Generation\",\"Max Capacity\", \"Available Capacity\", \"Prorrata\"])\n",
    "    .join(\n",
    "        procesor_ori.data.select([\"node\",\"datetime\",\"generator\",\"Prorrata\"]),\n",
    "        on=[\"node\",\"datetime\",\"generator\"],\n",
    "        how=\"inner\"\n",
    "    )\n",
    "    .rename({\"Prorrata\": \"Prorrata_cdc\", \"Prorrata_right\": \"Prorrata_ori\"})\n",
    "    .collect()\n",
    ")\n",
    "#compare_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "(\n",
    "    compare_data\n",
    "    .with_columns(\n",
    "        (pl.col(\"Available Capacity\") / pl.col(\"Max Capacity\")).alias(\"Porc. Available\"),\n",
    "        (pl.col(\"Prorrata_ori\") / pl.col(\"Max Capacity\")).alias(\"Porc. ori\"),\n",
    "        (pl.col(\"Prorrata_cdc\") / pl.col(\"Max Capacity\")).alias(\"Porc. cdc\"),\n",
    "        \n",
    "    )\n",
    "    #.filter(pl.col(\"generator\").eq(\"CHAPIQUINA\"))\n",
    "    #.filter(pl.col(\"datetime\").eq(datetime(2024,2,14,10)))\n",
    "    #.filter(pl.col(\"Prorrata_ori\").lt(pl.col(\"Prorrata_cdc\")))\n",
    "    .with_columns(\n",
    "        pl.when(pl.col(\"Porc. ori\").gt(pl.col(\"Porc. cdc\"))).then(True).otherwise(False).alias(\"Test\"),\n",
    "\n",
    "    )\n",
    "    #.filter(pl.col(\"Max Capacity\").lt(pl.col(\"Available Capacity\").max().over(\"generator\")))\n",
    "    #.filter(pl.col(\"Available Capacity\").max())\n",
    "    #.sort(\"datetime\")\n",
    "    #.head(30)\n",
    "    .write_csv(\"compare_data.csv\", datetime_format=\"%Y-%m-%d %T\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    procesor_cdc.data\n",
    "    #.filter(pl.col(\"generator\").eq(\"CHAPIQUINA\"))\n",
    "    .group_by(\"datetime\")\n",
    "    .agg(\n",
    "        Sum_Gen = pl.sum(\"Generation\"),\n",
    "        Sum_Available = pl.sum(\"Available Capacity\"), \n",
    "        Sum_Prorrata = pl.sum(\"Prorrata\"),\n",
    "        Sum_Error = pl.sum(\"Error\"),\n",
    "        Error = pl.sum(\"Prorrata\") - pl.sum(\"Generation\")\n",
    "    )\n",
    "    .sort(\"datetime\")\n",
    "    .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    procesor_ori.data\n",
    "    #.filter(pl.col(\"generator\").eq(\"CHAPIQUINA\"))\n",
    "    .group_by(\"datetime\")\n",
    "    .agg(\n",
    "        Sum_Gen = pl.sum(\"Generation\"),\n",
    "        Sum_Available = pl.sum(\"Available Capacity\"), \n",
    "        Sum_Prorrata = pl.sum(\"Prorrata\"),\n",
    "        Sum_Error = pl.sum(\"Error\"),\n",
    "        Error = pl.sum(\"Prorrata\") - pl.sum(\"Generation\")\n",
    "    )\n",
    "    .sort(\"datetime\")\n",
    "    .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    procesor_ori.data\n",
    "    .filter(\n",
    "        pl.col(\"Available Capacity\").gt(pl.col(\"Max Capacity\"))\n",
    "    )\n",
    "    .select(\n",
    "        pl.col(\"generator\").unique(),\n",
    "    )\n",
    "    .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRUEBA DE CASOS ERROR\n",
    "\n",
    "Que pasa si no hay cmg menor a 0? o no hay curtailment? ... armar caso apra esto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from prorrata.extract import DataExtractor\n",
    "\n",
    "\n",
    "path_prg = r\"C:\\Users\\felipe.bastidas\\PyProyectos\\Test_data\\PRG20240214\"\n",
    "PATH_PMGD_EXCLUDE =  r\"C:\\Users\\felipe.bastidas\\PyProyectos\\Test_data\\Otros\\Lista_PMGDs.xlsx\"\n",
    "PATH_BANNED_GENERATORS = r\"C:\\Users\\felipe.bastidas\\PyProyectos\\Test_data\\Otros\\Centrales_Vetadas.xlsx\"\n",
    "PATH_ACCDB_INPUT = r\"Datos/Model PRGdia_Full_Definitivo Solution/Model PRGdia_Full_Definitivo Solution.accdb\"\n",
    "\n",
    "data = DataExtractor(\n",
    "    Path(path_prg).joinpath(PATH_ACCDB_INPUT),\n",
    "    Path(PATH_PMGD_EXCLUDE),\n",
    "    Path(PATH_BANNED_GENERATORS)\n",
    ")\n",
    "\n",
    "data.extract_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.check_curtailment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "(\n",
    "    data.gen\n",
    "    .filter(pl.col(\"property\").eq(\"Capacity Curtailed\"))\n",
    "    .select(pl.col(\"value\").sum())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prorrata.transform import DataProcessor\n",
    "\n",
    "row, _ = data.cmg.shape\n",
    "\n",
    "if row == 0:\n",
    "    raise ValueError(\"No hay curtailment\")\n",
    "\n",
    "data_processor = DataProcessor(data)\n",
    "data_processor.process_prorrata()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
